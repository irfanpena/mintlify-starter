---
title: 'Token Usage'
description: 'This guide explains how token usage is calculated for both **AI Scrapers** and **Manual Scrapers**.'
---


MrScraper uses a **token-based system** to measure how much compute power and resources your scrapers use.


## AI Scraper Token Usage

AI Scrapers consume tokens based on the following factors:

| Usage Type        | Description                                                                     | Conversion Rate                   |
| ----------------- | ------------------------------------------------------------------------------- | --------------------------------- |
| **Run Tracking**  | Each scraper run consumes 1 token for system trace tracking.                    | 1 token per run                   |
| **Runtime**       | Time spent processing your task.                                                | 1 token per 30 seconds of runtime |
| **Input Tokens**  | The amount of text data (prompts, instructions, or pages) sent to the AI model. | 1 token per 30,000 input tokens   |
| **Output Tokens** | The amount of data generated by the AI model (responses or extracted results).  | 1 token per 7,500 output tokens   |

<Note>
  - Each run automatically includes trace tracking for debugging and performance monitoring.  
  - Input and output tokens are based on how much text the AI model processes and generates.
  - AI Scrapers tend to consume more tokens due to model processing.
</Note>

### Example

If your AI scraper:

* Runs for **90 seconds**
* Processes **60,000 input tokens**
* Produces **15,000 output tokens**

The total token usage would be:

| Component | Calculation     | Tokens |
| --------- | --------------- | ------ |
| Runtime   | 90 ÷ 30         | 3      |
| Input     | 60,000 ÷ 30,000 | 2      |
| Output    | 15,000 ÷ 7,500  | 2      |
| Run Trace | Fixed           | 1      |
| Total |       | 8      |


## Manual Scraper Token Usage

Manual Scrapers (non-AI) use tokens based on **runtime** and **bandwidth usage**.

| Usage Type    | Description                            | Conversion Rate        |
| ------------- | -------------------------------------- | ---------------------- |
| **Runtime**   | Time your scraper runs.                | 1 token per 30 seconds |
| **Bandwidth** | Amount of data downloaded or uploaded. | 1 token per 2 MB       |


### Example

If your manual scraper:

* Runs for **60 seconds**
* Uses **10 MB** of bandwidth

Then token usage will be:

| Component | Calculation | Tokens |
| --------- | ----------- | ------ |
| Runtime   | 60 ÷ 30     | 2      |
| Bandwidth | 10 ÷ 2      | 5      |
| Total |       | 7      |



<Tip>
Shorter runtimes and optimized prompts help reduce token usage.  
</Tip>

## Why Token Usage Varies

Several factors affect how many tokens a scraping task consumes:

- **Website Complexity**: Websites with heavy JavaScript, dynamic content, or multiple requests take longer to load and process, increasing runtime and token usage.

- **Page Size and Content Density**: Larger pages with long articles, embedded videos, or extensive metadata produce more input text for AI models to process.

- **Data Volume**: Extracting large sets of data (for example, multiple listings or paginated results) requires more compute and bandwidth.

- **AI Processing Load**: For AI Scrapers, complex instructions or unstructured data increase both input and output token usage, since the model must interpret and generate more text.
